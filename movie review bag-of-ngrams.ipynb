{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results first\n",
    "#### Because why not. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Standard architecture**: \n",
    "2-gram, embed 100, vocab 10000, tokenization scheme (same as lab),   \n",
    "learning_rate = 0.005, num_epochs = 4. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Hyperparameters                        | val_accuracy (%) |\n",
    "|----------------------------------------|------------------|\n",
    "| Standard                               | 83.16            |\n",
    "| 1-gram                                 | 86.80            |\n",
    "| 3-gram                                 | 77.48            |\n",
    "| 4-gram                                 | 71.0             |\n",
    "| 1-gram + tok_scheme: remove stop words | 88.48            |\n",
    "| vocab: 30,000                          | 85.48            |\n",
    "| vocab: 50,000                          | 85.82            |\n",
    "| embedding: 300                         | 83.2             |\n",
    "| embedding: 500                         | 83.48            |\n",
    "| 1-gram, embed 300, vocab 50k           | 88.02            |\n",
    "| 1-gram, embed 500, vocab 50k           | 87.90            |\n",
    "| 2-gram, embed 300, vocab 50k           | 85.28            |\n",
    "| 2-gram, embed 500, vocab 50k           | 85.52            |\n",
    "| 3-gram, embed 300, vocab 50k           | 81.21            |\n",
    "| 3-gram, embed 500, vocab 50k           | 81.36            |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now the code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-time loading of data from text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import spacy\n",
    "import string\n",
    "from os import listdir\n",
    "import pickle as pkl\n",
    "import torch\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from spacy.lang.en.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Data loading code inspired from: https://machinelearningmastery.com/prepare-movie-review-data-sentiment-analysis/\n",
    "'''\n",
    "\n",
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "    file = open(filename, 'r')\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text\n",
    " \n",
    "# load all docs in a directory\n",
    "def process_docs(directory, data):\n",
    "    # walk through all files in the folder\n",
    "    i = 0\n",
    "    for filename in listdir(directory):\n",
    "        # skip files that do not have the right extension\n",
    "        if not filename.endswith(\".txt\"):\n",
    "            continue\n",
    "        # create the full path of the file to open\n",
    "        path = directory + '/' + filename\n",
    "        # load document\n",
    "        data.append(load_doc(path))\n",
    "        i += 1\n",
    "    print(\"Loaded {} files from {}\".format(i, directory))\n",
    "    return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_DIR = '/Users/vrajiv/Desktop/NLP Class/lab3/aclImdb/train/'\n",
    "TEST_DATA_DIR = '/Users/vrajiv/Desktop/NLP Class/lab3/aclImdb/test/'\n",
    "TRAIN_VAL_SPLIT = 20000\n",
    "SEED = 1\n",
    "\n",
    "full_train_data = []\n",
    "\n",
    "num_pos = process_docs(TRAIN_DATA_DIR + 'pos', full_train_data)\n",
    "num_neg = process_docs(TRAIN_DATA_DIR + 'neg', full_train_data)\n",
    "\n",
    "full_train_labels = [0] * (num_pos + num_neg)\n",
    "for i in range(num_pos):\n",
    "    full_train_labels[i] = 1\n",
    "\n",
    "# randomly shuffle data \n",
    "# do it for labels as well, so they get shuffled the same way\n",
    "random.Random(SEED).shuffle(full_train_data)\n",
    "random.Random(SEED).shuffle(full_train_labels)\n",
    "\n",
    "# Split train data into actual train and validation sets\n",
    "train_data = full_train_data[:TRAIN_VAL_SPLIT]\n",
    "val_data = full_train_data[TRAIN_VAL_SPLIT:]\n",
    "\n",
    "# Same for labels\n",
    "train_labels = full_train_labels[:TRAIN_VAL_SPLIT]\n",
    "val_labels = full_train_labels[TRAIN_VAL_SPLIT:]\n",
    "\n",
    "print(\"Total length of train data: {}\".format(len(train_data)))\n",
    "print(\"Total length of validation data: {}\".format(len(val_data)))\n",
    "\n",
    "\n",
    "###\n",
    "### TEST DATA \n",
    "###\n",
    "\n",
    "test_data = []\n",
    "\n",
    "num_pos = process_docs(TEST_DATA_DIR + 'pos', test_data)\n",
    "num_neg = process_docs(TEST_DATA_DIR + 'neg', test_data)\n",
    "\n",
    "test_labels = [0] * (num_pos + num_neg)\n",
    "for i in range(num_pos):\n",
    "    test_labels[i] = 1\n",
    "\n",
    "# randomly shuffle data\n",
    "random.Random(SEED).shuffle(test_data)\n",
    "random.Random(SEED).shuffle(test_labels)\n",
    "print(\"Total length of test data: {}\".format(len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify that labels (sentiment) and reviews match in train data. \n",
    "def verify_match(data, labels):\n",
    "    rand_seed = random.randint(1, 101)\n",
    "    print(random.Random(rand_seed).choice(data))\n",
    "    print(random.Random(rand_seed).choice(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_match(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_match(val_data, val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing train/val/test as lists -- pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('movie_review_train_data.p', 'wb') as f:\n",
    "    pkl.dump(train_data, f)\n",
    "    \n",
    "with open('movie_review_train_labels.p', 'wb') as f:\n",
    "    pkl.dump(train_labels, f)\n",
    "    \n",
    "with open('movie_review_val_data.p', 'wb') as f:\n",
    "    pkl.dump(val_data, f)\n",
    "    \n",
    "with open('movie_review_val_labels.p', 'wb') as f:\n",
    "    pkl.dump(val_labels, f)\n",
    "    \n",
    "with open('movie_review_test_data.p', 'wb') as f:\n",
    "    pkl.dump(test_data, f)\n",
    "    \n",
    "with open('movie_review_test_labels.p', 'wb') as f:\n",
    "    pkl.dump(test_labels, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching train/val/test data -- pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pkl.load(open(\"movie_review_train_data.p\", \"rb\"))\n",
    "train_labels = pkl.load(open(\"movie_review_train_labels.p\", \"rb\"))\n",
    "val_data = pkl.load(open(\"movie_review_val_data.p\", \"rb\"))\n",
    "val_labels = pkl.load(open(\"movie_review_val_labels.p\", \"rb\"))\n",
    "test_data = pkl.load(open(\"movie_review_test_data.p\", \"rb\"))\n",
    "test_labels = pkl.load(open(\"movie_review_test_labels.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This definitely is NOT the intellectual film with profound mission, so I really don't think there is too much not to understand to in case you aren't Czech.<br /><br />It's just a comedy. The humor is simple, pretty funny and sometimes, maybe, little morbid. Some actors and characters are very similar to Samotári (2000) (Jirí Machácek, Ivan Trojan, Vladimír Dlouhý) so the authors are. But it doesn't matter, the genre is really different and these two films shouldn't be compared in this way. Jedna ruka netleská won't try to give you a lesson, it will try to make you laugh and there is some chance it will succeed.<br /><br />Not bad film, not the ingenious one, but I enjoyed it. Some scenes are truly worth seeing.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some things I notice from examining training set data\n",
    "\n",
    "I see ... html tags, hex codes. On average, good grammar so that's cool.   \n",
    "Filter out html tags + hex codes? Not sure.  \n",
    "Also not sure if I want to filter out exclamation marks/question marks. That might be very useful for expressing a sentiment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization (standard scheme from lab + 2nd scheme: remove stop words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apple', 'looking', 'buying', 'u.k.', 'startup', '1', 'billion']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = spacy.load('en_core_web_sm')\n",
    "punctuations = string.punctuation\n",
    "\n",
    "# lowercase and remove punctuation as well as stop words (for 2nd tokenization scheme\n",
    "def tokenize(sent):\n",
    "    tokens = tokenizer(sent)\n",
    "    return [token.text.lower() for token in tokens if (token.text not in punctuations and token.text not in STOP_WORDS)]\n",
    "\n",
    "# Example\n",
    "tokens = tokenize(u'Apple is looking at buying U.K. startup for $1 billion')\n",
    "print (tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing val data\n",
      "Tokenizing test data\n",
      "Tokenizing train data\n"
     ]
    }
   ],
   "source": [
    "def tokenize_dataset(dataset):\n",
    "    token_dataset = []\n",
    "    # we are keeping track of all tokens in dataset \n",
    "    # in order to create vocabulary later\n",
    "    all_tokens = []\n",
    "    \n",
    "    for sample in dataset:\n",
    "        tokens = tokenize(sample)\n",
    "        token_dataset.append(tokens)\n",
    "        all_tokens += tokens\n",
    "\n",
    "    return token_dataset, all_tokens\n",
    "\n",
    "# # val set tokens\n",
    "# print (\"Tokenizing val data\")\n",
    "# val_data_tokens, _ = tokenize_dataset(val_data)\n",
    "# pkl.dump(val_data_tokens, open(\"movie_review_val_data_tokens.p\", \"wb\"))\n",
    "\n",
    "# # test set tokens\n",
    "# print (\"Tokenizing test data\")\n",
    "# test_data_tokens, _ = tokenize_dataset(test_data)\n",
    "# pkl.dump(test_data_tokens, open(\"movie_review_test_data_tokens.p\", \"wb\"))\n",
    "\n",
    "# # train set tokens\n",
    "# print (\"Tokenizing train data\")\n",
    "# train_data_tokens, all_train_tokens = tokenize_dataset(train_data)\n",
    "# pkl.dump(train_data_tokens, open(\"movie_review_train_data_tokens.p\", \"wb\"))\n",
    "# pkl.dump(all_train_tokens, open(\"movie_review_all_train_tokens.p\", \"wb\"))\n",
    "\n",
    "###\n",
    "### REMOVING STOP WORDS\n",
    "###\n",
    "\n",
    "# # # val set tokens\n",
    "# print (\"Tokenizing val data\")\n",
    "# val_data_tokens, _ = tokenize_dataset(val_data)\n",
    "# pkl.dump(val_data_tokens, open(\"movie_review_val_data_tokens_stop_words.p\", \"wb\"))\n",
    "\n",
    "# # # test set tokens\n",
    "# print (\"Tokenizing test data\")\n",
    "# test_data_tokens, _ = tokenize_dataset(test_data)\n",
    "# pkl.dump(test_data_tokens, open(\"movie_review_test_data_tokens_stop_words.p\", \"wb\"))\n",
    "\n",
    "# # # train set tokens\n",
    "# print (\"Tokenizing train data\")\n",
    "# train_data_tokens, all_train_tokens = tokenize_dataset(train_data)\n",
    "# pkl.dump(train_data_tokens, open(\"movie_review_train_data_tokens_stop_words.p\", \"wb\"))\n",
    "# pkl.dump(all_train_tokens, open(\"movie_review_all_train_tokens_stop_words.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading tokenized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Test dataset size is 25000\n",
      "Total number of tokens in train dataset is 2519291\n"
     ]
    }
   ],
   "source": [
    "# load tokenized train, val and test datasets\n",
    "# train_data_tokens = pkl.load(open(\"movie_review_train_data_tokens.p\", \"rb\"))\n",
    "# all_train_tokens = pkl.load(open(\"movie_review_all_train_tokens.p\", \"rb\"))\n",
    "# val_data_tokens = pkl.load(open(\"movie_review_val_data_tokens.p\", \"rb\"))\n",
    "# test_data_tokens = pkl.load(open(\"movie_review_test_data_tokens.p\", \"rb\"))\n",
    "\n",
    "### STOP WORDS -- scheme\n",
    "train_data_tokens = pkl.load(open(\"movie_review_train_data_tokens_stop_words.p\", \"rb\"))\n",
    "all_train_tokens = pkl.load(open(\"movie_review_all_train_tokens_stop_words.p\", \"rb\"))\n",
    "val_data_tokens = pkl.load(open(\"movie_review_val_data_tokens_stop_words.p\", \"rb\"))\n",
    "test_data_tokens = pkl.load(open(\"movie_review_test_data_tokens_stop_words.p\", \"rb\"))\n",
    "\n",
    "# double checking\n",
    "print (\"Train dataset size is {}\".format(len(train_data_tokens)))\n",
    "print (\"Val dataset size is {}\".format(len(val_data_tokens)))\n",
    "print (\"Test dataset size is {}\".format(len(test_data_tokens)))\n",
    "\n",
    "print (\"Total number of tokens in train dataset is {}\".format(len(all_train_tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build vocabulary from most common tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "# save index 0 for unk and 1 for pad\n",
    "PAD_IDX = 0\n",
    "UNK_IDX = 1\n",
    "\n",
    "'''\n",
    "Inspired from: http://locallyoptimal.com/blog/2013/01/20/elegant-n-gram-generation-in-python/\n",
    "'''\n",
    "def generate_bag_ngrams(n, tokens):\n",
    "    return zip(*[tokens[i:] for i in range(n)])\n",
    "\n",
    "def build_vocab(all_tokens):\n",
    "    # Returns:\n",
    "    # id2token: list of tokens, where id2token[i] returns token that corresponds to token i\n",
    "    # token2id: dictionary where keys represent tokens and corresponding values represent indices\n",
    "    token_counter = Counter(all_tokens)\n",
    "    vocab, count = zip(*token_counter.most_common(VOCAB_SIZE))\n",
    "    id2token = list(vocab)\n",
    "    token2id = dict(zip(vocab, range(2,2+len(vocab)))) \n",
    "    id2token = ['<pad>', '<unk>'] + id2token\n",
    "    token2id['<pad>'] = PAD_IDX \n",
    "    token2id['<unk>'] = UNK_IDX\n",
    "    return token2id, id2token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"One-hot encoding\"\n",
    "#### Represent each movie review as a vector of indices in our vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert token to id in the dataset\n",
    "def token2index_dataset(tokens_data):\n",
    "    indices_data = []\n",
    "    for tokens in tokens_data:\n",
    "        index_list = [token2id[token] if token in token2id else UNK_IDX for token in tokens]\n",
    "        indices_data.append(index_list)\n",
    "    return indices_data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining PyTorch Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SENTENCE_LENGTH = 200\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MovieReviewDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Class that represents a train/validation/test dataset that's readable for PyTorch\n",
    "    Note that this class inherits torch.utils.data.Dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_list, target_list):\n",
    "        \"\"\"\n",
    "        @param data_list: list of movie review tokens \n",
    "        @param target_list: list of movie review targets \n",
    "\n",
    "        \"\"\"\n",
    "        self.data_list = data_list\n",
    "        self.target_list = target_list\n",
    "        assert (len(self.data_list) == len(self.target_list))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "        \n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"\n",
    "        Triggered when you call dataset[i]\n",
    "        \"\"\"\n",
    "        \n",
    "        token_idx = self.data_list[key][:MAX_SENTENCE_LENGTH]\n",
    "        label = self.target_list[key]\n",
    "        return [token_idx, len(token_idx), label]\n",
    "\n",
    "def moviereview_collate_func(batch):\n",
    "    \"\"\"\n",
    "    Customized function for DataLoader that dynamically pads the batch so that all \n",
    "    data have the same length\n",
    "    \"\"\"\n",
    "    data_list = []\n",
    "    label_list = []\n",
    "    length_list = []\n",
    "    #print(\"collate batch: \", batch[0][0])\n",
    "    #batch[0][0] = batch[0][0][:MAX_SENTENCE_LENGTH]\n",
    "    for datum in batch:\n",
    "        label_list.append(datum[2])\n",
    "        length_list.append(datum[1])\n",
    "    # padding\n",
    "    for datum in batch:\n",
    "        padded_vec = np.pad(np.array(datum[0]), \n",
    "                                pad_width=((0,MAX_SENTENCE_LENGTH-datum[1])), \n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        data_list.append(padded_vec)\n",
    "    return [torch.from_numpy(np.array(data_list)), torch.LongTensor(length_list), torch.LongTensor(label_list)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Bag-of-Ngrams model in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BagOfWords(nn.Module):\n",
    "    \"\"\"\n",
    "    BagOfWords classification model\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, emb_dim):\n",
    "        \"\"\"\n",
    "        @param vocab_size: size of the vocabulary. \n",
    "        @param emb_dim: size of the word embedding\n",
    "        \"\"\"\n",
    "        super(BagOfWords, self).__init__()\n",
    "        # pay attention to padding_idx \n",
    "        self.embed = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n",
    "        self.linear = nn.Linear(emb_dim,2)\n",
    "    \n",
    "    def forward(self, data, length):\n",
    "        \"\"\"\n",
    "        \n",
    "        @param data: matrix of size (batch_size, max_sentence_length). Each row in data represents a \n",
    "            review that is represented using n-gram index. Note that they are padded to have same length.\n",
    "        @param length: an int tensor of size (batch_size), which represents the non-trivial (excludes padding)\n",
    "            length of each sentences in the data.\n",
    "        \"\"\"\n",
    "        out = self.embed(data)\n",
    "        out = torch.sum(out, dim=1)\n",
    "        out /= length.view(length.size()[0],1).expand_as(out).float()\n",
    "     \n",
    "        # Apply the linear function to get our logit (real numbers)\n",
    "        logit = self.linear(out.float())\n",
    "        \n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for testing the model\n",
    "def test_model(loader, model):\n",
    "    \"\"\"\n",
    "    Help function that tests the model's performance on a dataset\n",
    "    @param: loader - data loader for the dataset to test against\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    for data, lengths, labels in loader:\n",
    "        data_batch, length_batch, label_batch = data, lengths, labels\n",
    "        outputs = F.softmax(model(data_batch, length_batch), dim=1)\n",
    "        predicted = outputs.max(1, keepdim=True)[1]\n",
    "#         predicted = torch.tensor([1 if x >= 0.5 else 0 for x in outputs[:, 1]]      )\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels.view_as(predicted)).sum().item()\n",
    "    return (100 * correct / total)\n",
    "\n",
    "def train_model(model,\n",
    "              lr = 0.005, \n",
    "              num_epochs = 4, \n",
    "              criterion = nn.CrossEntropyLoss()):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr) # wd: linear\n",
    "    losses = []\n",
    "    xs = 0\n",
    "    val_accs = []\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (data, lengths, labels) in enumerate(train_loader):\n",
    "            model.train()\n",
    "            data_batch, length_batch, label_batch = data, lengths, labels\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data_batch, length_batch)\n",
    "            loss = criterion(outputs, label_batch)\n",
    "            losses.append(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # validate every 100 iterations\n",
    "            if i > 0 and i % 100 == 0:\n",
    "                # validate\n",
    "                val_acc = test_model(val_loader, model)\n",
    "                xs = xs + 100\n",
    "                val_accs.append(val_acc)\n",
    "                print('Epoch: [{}/{}], Step: [{}/{}], Validation Acc: {}'.format( \n",
    "                           epoch+1, num_epochs, i+1, len(train_loader), val_acc))\n",
    "    return losses, xs, val_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_bigrams = list(generate_bag_ngrams(2, all_train_tokens))\n",
    "all_unigrams = list(generate_bag_ngrams(1, all_train_tokens))\n",
    "combined_one_two = all_bigrams + all_unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(combined_one_two[5000000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in range(len(id2token)):\n",
    "    if len(id2token[i]) == 2:\n",
    "        count += 1\n",
    "print(\"Length of idtoken is {}\".format(len(id2token)))\n",
    "print(\"Number of 1-gram tokens is {}\".format(len(id2token) - count))\n",
    "print(\"Number of 2-gram tokens is {}\".format(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_token_id = random.randint(0, len(id2token)-1)\n",
    "random_token = id2token[random_token_id]\n",
    "print(random_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full model run in one script (for quick hyperparameter tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token id 14111 ; token ('initial', 'release')\n",
      "Token ('initial', 'release'); token id 14111\n",
      "Train dataset size is 20000\n",
      "Val dataset size is 5000\n",
      "Test dataset size is 25000\n",
      "tensor([[    1,     1,     1,  ...,     0,     0,     0],\n",
      "        [    1,     1,   147,  ...,     0,     0,     0],\n",
      "        [ 6092,     1,     1,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [41895,     1,     1,  ...,     0,     0,     0],\n",
      "        [ 9207,  8558,     1,  ...,     0,     0,     0],\n",
      "        [    1, 38581, 30117,  ...,     0,     0,     0]])\n",
      "tensor([139,  56,  90,  75, 200, 200, 103, 200, 200, 150, 200, 103, 149,  26,\n",
      "         65, 116, 121,  17, 104, 140, 129,  65, 146,  95, 120, 200, 200,  44,\n",
      "         72,  23,  79, 107])\n",
      "tensor([0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0,\n",
      "        0, 1, 0, 0, 1, 0, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = 50000\n",
    "NGRAM_SIZE = 2\n",
    "EMBED_DIM = 300\n",
    "LEARNING_RATE = 0.005\n",
    "NUM_EPOCHS = 4\n",
    "\n",
    "# Building the vocabulary\n",
    "# UNCOMMENT FOR ORIGINAL tokenization scheme\n",
    "token2id, id2token = build_vocab(generate_bag_ngrams(NGRAM_SIZE, all_train_tokens))\n",
    "## TRYING MIXTURE of 1-grams and 2-grams\n",
    "# token2id, id2token = build_vocab(combined_one_two)\n",
    "\n",
    "# Lets check the dictionary by loading random token from it\n",
    "random_token_id = random.randint(0, len(id2token)-1)\n",
    "random_token = id2token[random_token_id]\n",
    "\n",
    "print (\"Token id {} ; token {}\".format(random_token_id, id2token[random_token_id]))\n",
    "print (\"Token {}; token id {}\".format(random_token, token2id[random_token]))\n",
    "\n",
    "# UNCOMMENT FOR ORIGINAL tokenization scheme\n",
    "ngram_train_data_tokens = [list(generate_bag_ngrams(NGRAM_SIZE, review)) for review in train_data_tokens]\n",
    "ngram_val_data_tokens = [list(generate_bag_ngrams(NGRAM_SIZE, review)) for review in val_data_tokens]\n",
    "ngram_test_data_tokens = [list(generate_bag_ngrams(NGRAM_SIZE, review)) for review in test_data_tokens]\n",
    "\n",
    "# ngram_train_data_tokens = [list(generate_bag_ngrams(1, review)) + list(generate_bag_ngrams(2, review)) for review in train_data_tokens]\n",
    "# ngram_val_data_tokens = [list(generate_bag_ngrams(1, review)) + list(generate_bag_ngrams(2, review)) for review in val_data_tokens]\n",
    "# ngram_test_data_tokens = [list(generate_bag_ngrams(1, review)) + list(generate_bag_ngrams(2, review)) for review in test_data_tokens]\n",
    "\n",
    "train_data_indices = token2index_dataset(ngram_train_data_tokens)\n",
    "val_data_indices = token2index_dataset(ngram_val_data_tokens)\n",
    "test_data_indices = token2index_dataset(ngram_test_data_tokens)\n",
    "\n",
    "# double checking\n",
    "print (\"Train dataset size is {}\".format(len(train_data_indices)))\n",
    "print (\"Val dataset size is {}\".format(len(val_data_indices)))\n",
    "print (\"Test dataset size is {}\".format(len(test_data_indices)))\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "train_dataset = MovieReviewDataset(train_data_indices, train_labels)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=moviereview_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "val_dataset = MovieReviewDataset(val_data_indices, val_labels)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=moviereview_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_dataset = MovieReviewDataset(test_data_indices, test_labels)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=moviereview_collate_func,\n",
    "                                           shuffle=False)\n",
    "\n",
    "for i, (data, lengths, labels) in enumerate(train_loader):\n",
    "    print (data)\n",
    "    print(lengths)\n",
    "    print (labels)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/4], Step: [101/625], Validation Acc: 55.44\n",
      "Epoch: [1/4], Step: [201/625], Validation Acc: 69.24\n",
      "Epoch: [1/4], Step: [301/625], Validation Acc: 80.48\n",
      "Epoch: [1/4], Step: [401/625], Validation Acc: 78.68\n",
      "Epoch: [1/4], Step: [501/625], Validation Acc: 79.26\n",
      "Epoch: [1/4], Step: [601/625], Validation Acc: 85.16\n",
      "Epoch: [2/4], Step: [101/625], Validation Acc: 85.1\n",
      "Epoch: [2/4], Step: [201/625], Validation Acc: 84.76\n",
      "Epoch: [2/4], Step: [301/625], Validation Acc: 83.02\n",
      "Epoch: [2/4], Step: [401/625], Validation Acc: 83.04\n",
      "Epoch: [2/4], Step: [501/625], Validation Acc: 84.1\n",
      "Epoch: [2/4], Step: [601/625], Validation Acc: 83.76\n",
      "Epoch: [3/4], Step: [101/625], Validation Acc: 84.2\n",
      "Epoch: [3/4], Step: [201/625], Validation Acc: 83.56\n",
      "Epoch: [3/4], Step: [301/625], Validation Acc: 84.18\n",
      "Epoch: [3/4], Step: [401/625], Validation Acc: 83.78\n",
      "Epoch: [3/4], Step: [501/625], Validation Acc: 83.7\n",
      "Epoch: [3/4], Step: [601/625], Validation Acc: 83.76\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-cede39abd4e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m           criterion = nn.CrossEntropyLoss())\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-c11899d96555>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, lr, num_epochs, criterion)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0;31m# validate every 100 iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlpclass/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                     \u001b[0;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = BagOfWords(len(id2token), EMBED_DIM)\n",
    "\n",
    "losses, xs, val_accs = train_model(model,\n",
    "          lr = LEARNING_RATE, \n",
    "          num_epochs = NUM_EPOCHS, \n",
    "          criterion = nn.CrossEntropyLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Val Acc')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10, 5))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "loss_avg_vals = []\n",
    "for i in range(0, len(losses)-100, 100):\n",
    "    s = 0\n",
    "    avg = 0\n",
    "    for j in range(i, i+100):\n",
    "        s += losses[j]\n",
    "    avg = s/100.0\n",
    "    loss_avg_vals.append(avg)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(len(loss_avg_vals)), loss_avg_vals)\n",
    "plt.title('Training Curve')\n",
    "plt.xlabel('step')\n",
    "plt.ylabel('Train Loss')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(0, xs, 100), val_accs)\n",
    "plt.title('Validation Accuracy Curve')\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Val Acc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding 3 correct and 3 incorrect predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "eval_dataset = MovieReviewDataset(val_data_indices, val_labels)\n",
    "eval_loader = torch.utils.data.DataLoader(dataset=val_dataset, \n",
    "                                          batch_size=1,\n",
    "                                          collate_fn=moviereview_collate_func,\n",
    "                                          shuffle=False)\n",
    "\n",
    "i = 0\n",
    "incorrect_data = []\n",
    "correct_data = []\n",
    "corr_count = 0\n",
    "incorr_count = 0\n",
    "for data, lengths, labels in eval_loader:\n",
    "        data_batch, length_batch, label_batch = data, lengths, labels\n",
    "        outputs = F.softmax(model(data_batch, length_batch), dim=1)\n",
    "        predicted = outputs.max(1, keepdim=True)[1]\n",
    "        \n",
    "        if (predicted.squeeze().item() == labels.squeeze().item() and incorr_count <= 2):\n",
    "            incorr_count += 1\n",
    "            incorrect_data.append(val_data[i])\n",
    "        elif (predicted.squeeze().item() != labels.squeeze().item() and corr_count <= 2):\n",
    "            corr_count += 1\n",
    "            correct_data.append(val_data[i])\n",
    "        i += 1\n",
    "        \n",
    "        if corr_count == 3 and incorr_count == 3:\n",
    "            break       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(correct_data)):\n",
    "    print(correct_data[i] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(incorrect_data)):\n",
    "    print(incorrect_data[i] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(0).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"After training for {} epochs\".format(NUM_EPOCHS))\n",
    "print (\"Val Acc {}\".format(test_model(val_loader, model)))\n",
    "print (\"Test Acc {}\".format(test_model(test_loader, model)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
